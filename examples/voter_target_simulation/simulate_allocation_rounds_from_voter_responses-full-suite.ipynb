{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from darts.allocation import Allocator\n",
    "from darts.bandit import Bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... completed in 0.05365920066833496 seconds\n"
     ]
    }
   ],
   "source": [
    "# load in the data for the target pool\n",
    "start = time.time()\n",
    "file_loc = 'data/'\n",
    "allocation_pool_df = pd.read_csv(file_loc + 'target_voter_universe.csv')\n",
    "print(f\"... completed in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>probability</th>\n",
       "      <th>target_round</th>\n",
       "      <th>target_result</th>\n",
       "      <th>target_reward</th>\n",
       "      <th>target_regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model1_rf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>model2_lr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>model3_lr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>model4_xgb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>model5_lgbm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>model_baseline</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>model1_rf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>model2_lr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>model3_lr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>model4_xgb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_id        model_id  probability  target_round  target_result  \\\n",
       "0          0       model1_rf          0.0             0              0   \n",
       "1          0       model2_lr          1.0             0              0   \n",
       "2          0       model3_lr          0.0             0              0   \n",
       "3          0      model4_xgb          1.0             0              0   \n",
       "4          0     model5_lgbm          0.0             0              0   \n",
       "5          0  model_baseline          1.0             0              0   \n",
       "6          1       model1_rf          0.0             0              0   \n",
       "7          1       model2_lr          0.0             0              0   \n",
       "8          1       model3_lr          0.0             0              0   \n",
       "9          1      model4_xgb          0.0             0              0   \n",
       "\n",
       "   target_reward  target_regret  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "5              0              0  \n",
       "6              0              0  \n",
       "7              0              0  \n",
       "8              0              0  \n",
       "9              0              0  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocation_pool_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.54"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(allocation_pool_df.shape[0]/6)/250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... completed in 0.013453960418701172 seconds\n"
     ]
    }
   ],
   "source": [
    "# load in our target results\n",
    "start = time.time()\n",
    "file_loc = 'data/'\n",
    "target_results_df = pd.read_csv(file_loc + 'voter_responses.csv')\n",
    "print(f\"... completed in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>target_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_id  target_result\n",
       "0          0              1\n",
       "1          1              0\n",
       "2          3              0\n",
       "3          4              0\n",
       "4         16              1\n",
       "5         22              0\n",
       "6         26              0\n",
       "7         27              1\n",
       "8         29              0\n",
       "9         31              0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the column that indicates the id of an individual target\n",
    "target_id_col = 'target_id'\n",
    "\n",
    "# Specify the column that provides the confidence ranking (e.g. probability)\n",
    "# that any of the models have on this target resulting in a 'reward'\n",
    "# (e.g. the target outcome of the model)\n",
    "confidence_rank_col = 'probability'\n",
    "\n",
    "# Specify the column containing the names of the different 'arms' or\n",
    "# models we're using in the target pool\n",
    "arm_name_col = 'model_id'\n",
    "\n",
    "# Specify column to track the pool round\n",
    "pool_round_col = 'target_round'\n",
    "\n",
    "# Specify the column that indicates the 'result'\n",
    "result_col = 'target_result'\n",
    "\n",
    "# Specify the column that indicates the 'reward'\n",
    "reward_col = 'target_reward'\n",
    "\n",
    "# Specify the column that indicates the 'regret'\n",
    "regret_col = 'target_regret'\n",
    "\n",
    "# Specify the column that indicates which arm was 'picked'\n",
    "picked_col = 'model_picked'\n",
    "\n",
    "# Specify an initial allocation method across the pool of models. These must sum to 1.\n",
    "# For the simulation, we'll start with an equal allocation for each model.\n",
    "allocation_method = {\n",
    "    'model_baseline': (1/6),\n",
    "    'model1_rf': (1/6),\n",
    "    'model2_lr': (1/6),\n",
    "    'model3_lr': (1/6),\n",
    "    'model4_xgb': (1/6),\n",
    "    'model5_lgbm': (1/6)\n",
    "}\n",
    "\n",
    "# Specify number of rounds to simulate\n",
    "simulation_rounds = 50\n",
    "\n",
    "# Specify the number of targets to pull in the first round.\n",
    "num_targets = 250\n",
    "\n",
    "# Specify the allocation policy\n",
    "allocation_policy = 'UCB1'\n",
    "\n",
    "# Specify the allocation strategy\n",
    "allocation_strategy = 'round-robin'\n",
    "\n",
    "# Specify the allocation order\n",
    "allocation_order = 'best'\n",
    "\n",
    "# bandit parameters\n",
    "ucb_scale = 1.96\n",
    "epsilon = 0.1\n",
    "greed_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the file of responses for updating of results\n",
    "target_results_df = target_results_df.set_index([target_id_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = {\n",
    "    1: {'policy': 'UCB1',\n",
    "        'options': {'greed_factor': [1, 10, 100]},\n",
    "        'allocations': [('round-robin', 'best'), ('round-robin', 'random'), ('greedy', 'best')]\n",
    "       },\n",
    "    2: {'policy': 'Bayes_UCB',\n",
    "        'options': {'ucb_scale': [1, 2, 3],\n",
    "                    'greed_factor': [1, 10, 100]},\n",
    "        'allocations': [('round-robin', 'best'), ('round-robin', 'random'), ('greedy', 'best')]\n",
    "       },\n",
    "    3: {'policy': 'epsilon_greedy',\n",
    "        'options': {'epsilon': [0.05, 0.10, 0.25],\n",
    "                    'greed_factor': [1, 10, 100]},\n",
    "        'allocations': [('round-robin', 'best'), ('round-robin', 'random'), ('greedy', 'best')]\n",
    "       }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_perm_idx(idx, policy, ucb_scale, epsilon, greed_factor, strategy, order, pool_size, num_rounds):\n",
    "    return str(tuple(make_perm_dict(idx, policy, ucb_scale, epsilon, greed_factor, strategy, order, pool_size, num_rounds).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_perm_dict(idx, policy, ucb_scale, epsilon, greed_factor, strategy, order, pool_size, num_rounds):\n",
    "    return {\n",
    "        'perm_idx': idx,\n",
    "        'policy': policy,\n",
    "        'ucb_scale': ucb_scale,\n",
    "        'epsilon': epsilon,\n",
    "        'greed_factor': greed_factor,\n",
    "        'strategy': strategy,\n",
    "        'order': order,\n",
    "        'pool_size': pool_size,\n",
    "        'num_rounds': num_rounds\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_simulation(allocation_pool_df, target_results_df, allocation_method, allocation_policy, ucb_scale, epsilon, greed_factor, allocation_strategy, allocation_order, num_targets, simulation_rounds):\n",
    "    # Set up defaults - nothing picked yet\n",
    "    allocation_pool_df[picked_col] = 0\n",
    "    allocation_pool_df[pool_round_col] = 0\n",
    "    allocation_pool_df[reward_col] = 0\n",
    "    allocation_pool_df[regret_col] = 0\n",
    "\n",
    "    timesteps = {}\n",
    "\n",
    "    for allocation_round in range(1, simulation_rounds+1):\n",
    "\n",
    "        remaining_allocation_pool_df = pd.DataFrame.copy(allocation_pool_df[allocation_pool_df[pool_round_col]==0])\n",
    "\n",
    "        # set up an allocator\n",
    "        # TODO: I think this should be in the sequence of:\n",
    "        #  allocation_pool_df, arm_name_col, target_id_col, confidence_rank_col, allocation_method, strategy, order\n",
    "        # TODO: Would be good to explain that Allocator introduces a picked column to the dataframe. This is masked behavior.\n",
    "        #       I may rely on this column if I know about it, but not sure if it will ever go away?\n",
    "        allocator = Allocator(allocation_method, num_targets, remaining_allocation_pool_df, arm_name_col,\n",
    "                              confidence_rank_col, target_id_col, strategy=allocation_strategy,\n",
    "                              order=allocation_order) # another idea is to provide a dictionary mapping to simplify the calling interface\n",
    "\n",
    "        # retreive targets\n",
    "        targets = allocator.allocate_pool() # TODO: can we change this to allocator.retrieve_targets(num_targets) ? Also, might be nice to have a DF return option\n",
    "\n",
    "        # convert to dataframe\n",
    "        targets_df = pd.DataFrame(targets, columns=[target_id_col, arm_name_col])\n",
    "        targets_df[pool_round_col] = allocation_round\n",
    "        targets_df = targets_df[[target_id_col, pool_round_col]]\n",
    "\n",
    "        # join targets with universe of allocations\n",
    "        targets_df = targets_df.set_index([target_id_col])\n",
    "        allocation_pool_df = allocation_pool_df.set_index([target_id_col])\n",
    "        allocation_pool_df.update(targets_df)\n",
    "        allocation_pool_df = allocation_pool_df.reset_index()   \n",
    "\n",
    "        # add indicator for the arm we picked\n",
    "        target_arm_picked_df = pd.DataFrame(targets, columns=[target_id_col, arm_name_col])\n",
    "        target_arm_picked_df[picked_col] = 1\n",
    "        target_arm_picked_df = target_arm_picked_df[[target_id_col, arm_name_col, picked_col]]\n",
    "\n",
    "        # join target model we picked with the universe of allocations\n",
    "        target_arm_picked_df = target_arm_picked_df.set_index([target_id_col, arm_name_col])\n",
    "        allocation_pool_df = allocation_pool_df.set_index([target_id_col, arm_name_col])\n",
    "        allocation_pool_df.update(target_arm_picked_df)\n",
    "        allocation_pool_df = allocation_pool_df.reset_index()\n",
    "\n",
    "        # evaluate this allocation pool with the bandit\n",
    "        last_allocation_pool_df = allocation_pool_df[allocation_pool_df[pool_round_col] == allocation_round]\n",
    "\n",
    "        # sync up results\n",
    "        last_allocation_pool_df = last_allocation_pool_df.set_index([target_id_col])\n",
    "        last_allocation_pool_df.update(target_results_df)\n",
    "        last_allocation_pool_df = last_allocation_pool_df.reset_index(level=0)\n",
    "\n",
    "        # update results in the master pool set\n",
    "        allocation_pool_df = allocation_pool_df.set_index([target_id_col, arm_name_col, confidence_rank_col, pool_round_col, reward_col, regret_col, picked_col])\n",
    "        last_allocation_pool_df = last_allocation_pool_df.set_index([target_id_col, arm_name_col, confidence_rank_col, pool_round_col, reward_col, regret_col, picked_col])\n",
    "        allocation_pool_df.update(last_allocation_pool_df)\n",
    "        allocation_pool_df = allocation_pool_df.reset_index()\n",
    "\n",
    "        TP = allocation_pool_df[result_col] * allocation_pool_df[confidence_rank_col] * allocation_pool_df[picked_col]\n",
    "        TN = (1 - allocation_pool_df[result_col]) * (1 - allocation_pool_df[confidence_rank_col]) * (1 - allocation_pool_df[picked_col])\n",
    "        FN = allocation_pool_df[result_col] * (1 - allocation_pool_df[confidence_rank_col]) * (1 - allocation_pool_df[picked_col])\n",
    "        FP = (1 - allocation_pool_df[result_col]) * allocation_pool_df[confidence_rank_col] * allocation_pool_df[picked_col]\n",
    "\n",
    "        # update rewards from the results we synced\n",
    "        allocation_pool_df[reward_col] = TP\n",
    "\n",
    "        # update regrets from the results we synced\n",
    "        # regrets can be false positives or false negatives (type 1 and type 2 error)\n",
    "        allocation_pool_df[regret_col] = FN\n",
    "\n",
    "        # prepare a dataframe with our results from this round and all prior rounds for the bandit to evaluate\n",
    "        results_df = pd.DataFrame.copy(allocation_pool_df[allocation_pool_df[pool_round_col] != 0])\n",
    "\n",
    "        if results_df[(results_df[result_col]==1)&(results_df[reward_col]==1)].shape[0] == 0:\n",
    "            # no more results left after a steady state - reset selections to include possibilities from the other models\n",
    "\n",
    "            TP = allocation_pool_df[result_col] * allocation_pool_df[confidence_rank_col]\n",
    "            TN = (1 - allocation_pool_df[result_col]) * (1 - allocation_pool_df[confidence_rank_col])\n",
    "            FN = allocation_pool_df[result_col] * (1 - allocation_pool_df[confidence_rank_col])\n",
    "            FP = (1 - allocation_pool_df[result_col]) * allocation_pool_df[confidence_rank_col]\n",
    "\n",
    "            # update rewards from the results we synced\n",
    "            allocation_pool_df[reward_col] = TP\n",
    "\n",
    "            # update regrets from the results we synced\n",
    "            # regrets can be false positives or false negatives (type 1 and type 2 error)\n",
    "            allocation_pool_df[regret_col] = FN\n",
    "\n",
    "            # prepare a dataframe with just our results of this round for the bandit to evaluate\n",
    "            results_df = pd.DataFrame.copy(allocation_pool_df[allocation_pool_df[pool_round_col] == allocation_round])\n",
    "\n",
    "\n",
    "        # prepare dictionary of results for timestep tracking\n",
    "        stats = results_df[[arm_name_col, reward_col, regret_col]].groupby(arm_name_col).agg({reward_col:['count','sum'],\n",
    "                                                                                              regret_col:['sum']})\n",
    "        stats.columns = stats.columns.to_flat_index()\n",
    "        stats.columns = ['_'.join(tup).rstrip('_') for tup in stats.columns.values]\n",
    "        stats = pd.DataFrame(stats).reset_index()\n",
    "        stats.rename(columns={'target_reward_count': 'reward_evaluation_size', 'target_reward_sum': 'rewards', 'target_regret_sum':'regrets'}, inplace=True)\n",
    "        stats = stats.set_index([arm_name_col])\n",
    "        stats['allocation'] = 0.0\n",
    "        allocs = pd.DataFrame.from_dict(allocation_method, orient='index', columns = ['allocation'])\n",
    "        allocs.index.name=arm_name_col\n",
    "        stats.update(allocs)\n",
    "        stats = stats.reset_index()\n",
    "\n",
    "        timesteps[allocation_round] = stats.to_dict(orient='records')\n",
    "\n",
    "        # set up a multi-arm bandit and calculate allocations to each arm.\n",
    "        bandit = Bandit(results_df, arm_name_col, reward_col, regret_col, policy = allocation_policy, t = allocation_round, ucb_scale = ucb_scale, epsilon = epsilon, greed_factor = greed_factor)\n",
    "\n",
    "        # use these allocations for the next round\n",
    "        allocation_method = bandit.get_new_allocations()# bandit.make_allocs().set_index(arm_name_col)['allocation'].to_dict()\n",
    "        \n",
    "    print(\"Allocations after round\", allocation_round, \":\\n\", allocation_method)\n",
    "    #display(bandit.get_allocation_stats())\n",
    "    \n",
    "    return timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('perm_idx', 1), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.237623775645302, 'model5_lgbm': 0.17852678602966668, 'model2_lr': 0.16799011346253792, 'model1_rf': 0.15730073549588555, 'model_baseline': 0.13225704997401422, 'model4_xgb': 0.12630153939259361}\n",
      "(('perm_idx', 2), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9999999976382861, 'model_baseline': 6.321860788520792e-10, 'model2_lr': 6.074551547194424e-10, 'model4_xgb': 4.210607438640047e-10, 'model5_lgbm': 3.8740687966383325e-10, 'model1_rf': 3.1360495695778594e-10}\n",
      "(('perm_idx', 3), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model4_xgb': 5.750779349411461e-94, 'model2_lr': 7.259047812600424e-95, 'model_baseline': 3.133765107703038e-95, 'model5_lgbm': 1.3432682992622688e-95, 'model1_rf': 8.77072625300698e-96}\n",
      "(('perm_idx', 4), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.2882443658655263, 'model5_lgbm': 0.2100703012992237, 'model1_rf': 0.14757857187388151, 'model2_lr': 0.13902457088790313, 'model_baseline': 0.1185900129769547, 'model3_lr': 0.09649217709651052}\n",
      "(('perm_idx', 5), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.999999999999024, 'model_baseline': 3.464615596885709e-13, 'model1_rf': 1.7331878802745547e-13, 'model5_lgbm': 1.7331878802745547e-13, 'model2_lr': 1.4463425541786268e-13, 'model3_lr': 1.38166702151818e-13}\n",
      "(('perm_idx', 6), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model5_lgbm': 1.553005869779381e-127, 'model2_lr': 2.6265887632134243e-128, 'model_baseline': 1.6760409079461245e-128, 'model1_rf': 4.30177101512982e-129, 'model3_lr': 6.814344755012316e-130}\n",
      "(('perm_idx', 7), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 1), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.25713080152254714, 'model5_lgbm': 0.19163018742436533, 'model1_rf': 0.18140048778665394, 'model2_lr': 0.13269490294441616, 'model_baseline': 0.11986960787624072, 'model4_xgb': 0.11727401244577662}\n",
      "(('perm_idx', 8), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 10), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.999999998750467, 'model4_xgb': 3.7508240466545453e-10, 'model5_lgbm': 3.0335605171388163e-10, 'model1_rf': 2.4421922459384033e-10, 'model_baseline': 1.7089228281286605e-10, 'model2_lr': 1.5598304069076236e-10}\n",
      "(('perm_idx', 9), ('policy', 'UCB1'), ('ucb_scale', None), ('epsilon', None), ('greed_factor', 100), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model4_xgb': 3.12834108332759e-97, 'model5_lgbm': 2.0081735192187395e-97, 'model1_rf': 1.28656344306792e-97, 'model_baseline': 2.124342400894743e-98, 'model2_lr': 8.526559489938556e-99}\n",
      "(('perm_idx', 10), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.30224413667973105, 'model2_lr': 0.18380713949028485, 'model5_lgbm': 0.17381974009051668, 'model1_rf': 0.13956033781471142, 'model4_xgb': 0.10391245992911848, 'model_baseline': 0.0966561859956375}\n",
      "(('perm_idx', 11), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9999999999999994, 'model_baseline': 3.645051671435338e-16, 'model2_lr': 1.9924279012875484e-16, 'model4_xgb': 1.918077682085971e-17, 'model5_lgbm': 1.1118943164106961e-17, 'model1_rf': 2.439881352878817e-18}\n",
      "(('perm_idx', 12), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model4_xgb': 1.2603403545618725e-164, 'model2_lr': 4.129426121675004e-169, 'model_baseline': 8.019000423559743e-173, 'model5_lgbm': 3.8850961378738775e-174, 'model1_rf': 7.409086216725889e-180}\n",
      "(('perm_idx', 13), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.28811532843760207, 'model2_lr': 0.18743712076622304, 'model5_lgbm': 0.17397566053363944, 'model1_rf': 0.13950074245155467, 'model4_xgb': 0.11367028747749057, 'model_baseline': 0.09730086033349028}\n",
      "(('perm_idx', 14), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9999999999999983, 'model_baseline': 9.763383435807514e-16, 'model2_lr': 5.510305286410907e-16, 'model4_xgb': 9.832015716924494e-17, 'model5_lgbm': 3.6198163254472775e-17, 'model1_rf': 1.5821483690591934e-17}\n",
      "(('perm_idx', 15), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model5_lgbm': 5.594272858812989e-163, 'model2_lr': 4.456651588519913e-164, 'model_baseline': 4.4566515885194895e-164, 'model4_xgb': 2.2736308480607786e-166, 'model1_rf': 4.477108502945163e-170}\n",
      "(('perm_idx', 16), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.2777035059403163, 'model5_lgbm': 0.17205008234257346, 'model2_lr': 0.16325386759570729, 'model1_rf': 0.16307421548537884, 'model4_xgb': 0.11650311622652054, 'model_baseline': 0.10741521240950358}\n",
      "(('perm_idx', 17), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9999999999999947, 'model_baseline': 3.2918456412919838e-15, 'model2_lr': 1.62250169299761e-15, 'model4_xgb': 2.07148665005154e-16, 'model5_lgbm': 1.0055762943145913e-16, 'model1_rf': 3.4652742229642194e-17}\n",
      "(('perm_idx', 18), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model5_lgbm': 1.0795370363996642e-158, 'model2_lr': 9.717128152034804e-160, 'model_baseline': 9.717128152033576e-160, 'model4_xgb': 6.4145135946352e-162, 'model1_rf': 1.9318649572853138e-165}\n",
      "(('perm_idx', 19), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.554293877691493, 'model5_lgbm': 0.1959971705647258, 'model2_lr': 0.0989640974157295, 'model_baseline': 0.08412718298039469, 'model1_rf': 0.057008076673461694, 'model3_lr': 0.009609594674195438}\n",
      "(('perm_idx', 20), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model5_lgbm': 2.596182542040425e-21, 'model2_lr': 1.5084433990577359e-22, 'model3_lr': 8.421620416601261e-24, 'model1_rf': 2.5414554924012813e-24, 'model_baseline': 1.8236989914766414e-26}\n",
      "(('perm_idx', 21), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model5_lgbm': 1.0, 'model4_xgb': 4.268956026529969e-190, 'model2_lr': 4.0336112643802944e-208, 'model3_lr': 3.3922910874823728e-214, 'model1_rf': 2.492051236618382e-221, 'model_baseline': 5.396889712821243e-241}\n",
      "(('perm_idx', 22), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.5156225376759376, 'model5_lgbm': 0.2278962608397704, 'model1_rf': 0.08684786821838256, 'model2_lr': 0.06823398781006072, 'model_baseline': 0.0682339878100607, 'model3_lr': 0.03316535764578798}\n",
      "(('perm_idx', 23), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model5_lgbm': 1.6664855416945703e-20, 'model3_lr': 1.2191439575642527e-22, 'model1_rf': 7.55108765704134e-23, 'model2_lr': 2.661773604126329e-23, 'model_baseline': 4.2398444034393615e-24}\n",
      "(('perm_idx', 24), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model2_lr': 6.002013906158047e-178, 'model5_lgbm': 2.064529389368402e-221, 'model1_rf': 1.3083298424384602e-223, 'model_baseline': 2.0255475736200332e-228, 'model3_lr': 2.4119032712528997e-240}\n",
      "(('perm_idx', 25), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.5349507223239224, 'model5_lgbm': 0.16871637239628218, 'model2_lr': 0.10506330780797296, 'model1_rf': 0.10061419113878269, 'model_baseline': 0.049667687646369245, 'model3_lr': 0.040987718686670456}\n",
      "(('perm_idx', 26), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model3_lr': 2.2404909439339837e-21, 'model2_lr': 1.780814273465665e-22, 'model1_rf': 1.7808142734656579e-22, 'model5_lgbm': 1.0739962618221732e-22, 'model_baseline': 1.0739962618221603e-22}\n",
      "(('perm_idx', 27), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model1_rf': 5.552248929064647e-209, 'model2_lr': 5.552248929064301e-209, 'model5_lgbm': 1.1176350271827236e-210, 'model_baseline': 2.345381440773486e-218, 'model3_lr': 2.2089526964313033e-225}\n",
      "(('perm_idx', 28), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 1), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.3484634167062178, 'model1_rf': 0.2117592474008226, 'model5_lgbm': 0.20818327883763335, 'model4_xgb': 0.08956409944644979, 'model_baseline': 0.08120462800403787, 'model2_lr': 0.06082532960483856}\n",
      "(('perm_idx', 29), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 10), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model4_xgb': 8.407999850546188e-18, 'model5_lgbm': 2.4527307784938932e-18, 'model1_rf': 5.959492369150901e-19, 'model_baseline': 4.53447865013734e-21, 'model2_lr': 1.1478382213107173e-21}\n",
      "(('perm_idx', 30), ('policy', 'Bayes_UCB'), ('ucb_scale', 1), ('epsilon', None), ('greed_factor', 100), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model4_xgb': 3.4022966404530205e-190, 'model5_lgbm': 3.2360724297959276e-192, 'model1_rf': 2.4189019433896605e-194, 'model_baseline': 3.675137686993153e-204, 'model2_lr': 3.970149127664297e-210}\n",
      "(('perm_idx', 31), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 1), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.3284192313341858, 'model5_lgbm': 0.2079118984836885, 'model1_rf': 0.2033554356987397, 'model_baseline': 0.09085255854972363, 'model4_xgb': 0.08584450148834451, 'model2_lr': 0.08361637444531798}\n",
      "(('perm_idx', 32), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 10), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model4_xgb': 2.769686073443033e-17, 'model5_lgbm': 1.582148369059196e-17, 'model1_rf': 2.319158277534221e-18, 'model_baseline': 2.499255444278009e-20, 'model2_lr': 7.046588586559525e-21}\n",
      "(('perm_idx', 33), ('policy', 'Bayes_UCB'), ('ucb_scale', 2), ('epsilon', None), ('greed_factor', 100), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model4_xgb': 8.354196240179576e-184, 'model5_lgbm': 1.1012331926261231e-185, 'model1_rf': 1.1663794973901091e-187, 'model_baseline': 9.508378652181063e-197, 'model2_lr': 3.0184859628136868e-202}\n",
      "(('perm_idx', 34), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 1), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.31140869315612285, 'model5_lgbm': 0.20282378127068545, 'model1_rf': 0.1874363366433287, 'model2_lr': 0.11859844014836088, 'model_baseline': 0.09545804829610219, 'model4_xgb': 0.08427470048540002}\n",
      "(('perm_idx', 35), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 10), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9999999999999999, 'model4_xgb': 9.95303538228533e-17, 'model5_lgbm': 4.531824914253182e-17, 'model1_rf': 1.404413820023235e-17, 'model_baseline': 1.740848413121368e-19, 'model2_lr': 3.090399315045249e-20}\n",
      "(('perm_idx', 36), ('policy', 'Bayes_UCB'), ('ucb_scale', 3), ('epsilon', None), ('greed_factor', 100), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model4_xgb': 1.913615417813024e-178, 'model5_lgbm': 3.201453648039282e-180, 'model1_rf': 4.367350957072948e-182, 'model_baseline': 1.1807386833172885e-190, 'model2_lr': 7.945952943413879e-196}\n",
      "(('perm_idx', 37), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.95, 'model1_rf': 0.01, 'model2_lr': 0.01, 'model4_xgb': 0.01, 'model5_lgbm': 0.01, 'model_baseline': 0.01}\n",
      "(('perm_idx', 38), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 1.6701825701150942e-20, 'model2_lr': 1.6701825701150942e-20, 'model4_xgb': 1.6701825701150942e-20, 'model5_lgbm': 1.6701825701150942e-20, 'model_baseline': 1.6701825701150942e-20}\n",
      "(('perm_idx', 39), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 1.6890381970677758e-198, 'model2_lr': 1.6890381970677758e-198, 'model4_xgb': 1.6890381970677758e-198, 'model5_lgbm': 1.6890381970677758e-198, 'model_baseline': 1.6890381970677758e-198}\n",
      "(('perm_idx', 40), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9, 'model1_rf': 0.02, 'model2_lr': 0.02, 'model4_xgb': 0.02, 'model5_lgbm': 0.02, 'model_baseline': 0.02}\n",
      "(('perm_idx', 41), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 2.93680331857146e-17, 'model2_lr': 2.93680331857146e-17, 'model4_xgb': 2.93680331857146e-17, 'model5_lgbm': 2.93680331857146e-17, 'model_baseline': 2.93680331857146e-17}\n",
      "(('perm_idx', 42), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 4.7725295101856255e-166, 'model2_lr': 4.7725295101856255e-166, 'model4_xgb': 4.7725295101856255e-166, 'model5_lgbm': 4.7725295101856255e-166, 'model_baseline': 4.7725295101856255e-166}\n",
      "(('perm_idx', 43), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.75, 'model1_rf': 0.05, 'model2_lr': 0.05, 'model4_xgb': 0.05, 'model5_lgbm': 0.05, 'model_baseline': 0.05}\n",
      "(('perm_idx', 44), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9999999999913292, 'model1_rf': 1.7341529915682259e-12, 'model2_lr': 1.7341529915682259e-12, 'model4_xgb': 1.7341529915682259e-12, 'model5_lgbm': 1.7341529915682259e-12, 'model_baseline': 1.7341529915682259e-12}\n",
      "(('perm_idx', 45), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 2.459654426579843e-118, 'model2_lr': 2.459654426579843e-118, 'model4_xgb': 2.459654426579843e-118, 'model5_lgbm': 2.459654426579843e-118, 'model_baseline': 2.459654426579843e-118}\n",
      "(('perm_idx', 46), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.95, 'model1_rf': 0.01, 'model2_lr': 0.01, 'model3_lr': 0.01, 'model5_lgbm': 0.01, 'model_baseline': 0.01}\n",
      "(('perm_idx', 47), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model1_rf': 1.6701825701150942e-20, 'model2_lr': 1.6701825701150942e-20, 'model3_lr': 1.6701825701150942e-20, 'model5_lgbm': 1.6701825701150942e-20, 'model_baseline': 1.6701825701150942e-20}\n",
      "(('perm_idx', 48), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model1_rf': 1.6890381970677758e-198, 'model2_lr': 1.6890381970677758e-198, 'model3_lr': 1.6890381970677758e-198, 'model5_lgbm': 1.6890381970677758e-198, 'model_baseline': 1.6890381970677758e-198}\n",
      "(('perm_idx', 49), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model_baseline': 0.9, 'model1_rf': 0.02, 'model2_lr': 0.02, 'model3_lr': 0.02, 'model4_xgb': 0.02, 'model5_lgbm': 0.02}\n",
      "(('perm_idx', 50), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.9999999999999999, 'model1_rf': 2.9368033185714593e-17, 'model2_lr': 2.9368033185714593e-17, 'model3_lr': 2.9368033185714593e-17, 'model5_lgbm': 2.9368033185714593e-17, 'model_baseline': 2.9368033185714593e-17}\n",
      "(('perm_idx', 51), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model1_rf': 4.7725295101856255e-166, 'model2_lr': 4.7725295101856255e-166, 'model3_lr': 4.7725295101856255e-166, 'model5_lgbm': 4.7725295101856255e-166, 'model_baseline': 4.7725295101856255e-166}\n",
      "(('perm_idx', 52), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 1), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.75, 'model1_rf': 0.05, 'model2_lr': 0.05, 'model3_lr': 0.05, 'model5_lgbm': 0.05, 'model_baseline': 0.05}\n",
      "(('perm_idx', 53), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 10), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 0.9999999999913292, 'model1_rf': 1.7341529915682259e-12, 'model2_lr': 1.7341529915682259e-12, 'model3_lr': 1.7341529915682259e-12, 'model5_lgbm': 1.7341529915682259e-12, 'model_baseline': 1.7341529915682259e-12}\n",
      "(('perm_idx', 54), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 100), ('strategy', 'round-robin'), ('order', 'random'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model4_xgb': 1.0, 'model1_rf': 2.459654426579843e-118, 'model2_lr': 2.459654426579843e-118, 'model3_lr': 2.459654426579843e-118, 'model5_lgbm': 2.459654426579843e-118, 'model_baseline': 2.459654426579843e-118}\n",
      "(('perm_idx', 55), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 1), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.95, 'model1_rf': 0.01, 'model2_lr': 0.01, 'model4_xgb': 0.01, 'model5_lgbm': 0.01, 'model_baseline': 0.01}\n",
      "(('perm_idx', 56), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 10), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 1.6701825701150942e-20, 'model2_lr': 1.6701825701150942e-20, 'model4_xgb': 1.6701825701150942e-20, 'model5_lgbm': 1.6701825701150942e-20, 'model_baseline': 1.6701825701150942e-20}\n",
      "(('perm_idx', 57), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.05), ('greed_factor', 100), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 1.6890381970677758e-198, 'model2_lr': 1.6890381970677758e-198, 'model4_xgb': 1.6890381970677758e-198, 'model5_lgbm': 1.6890381970677758e-198, 'model_baseline': 1.6890381970677758e-198}\n",
      "(('perm_idx', 58), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 1), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9, 'model1_rf': 0.02, 'model2_lr': 0.02, 'model4_xgb': 0.02, 'model5_lgbm': 0.02, 'model_baseline': 0.02}\n",
      "(('perm_idx', 59), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 10), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 2.93680331857146e-17, 'model2_lr': 2.93680331857146e-17, 'model4_xgb': 2.93680331857146e-17, 'model5_lgbm': 2.93680331857146e-17, 'model_baseline': 2.93680331857146e-17}\n",
      "(('perm_idx', 60), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.1), ('greed_factor', 100), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 4.7725295101856255e-166, 'model2_lr': 4.7725295101856255e-166, 'model4_xgb': 4.7725295101856255e-166, 'model5_lgbm': 4.7725295101856255e-166, 'model_baseline': 4.7725295101856255e-166}\n",
      "(('perm_idx', 61), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 1), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.75, 'model1_rf': 0.05, 'model2_lr': 0.05, 'model4_xgb': 0.05, 'model5_lgbm': 0.05, 'model_baseline': 0.05}\n",
      "(('perm_idx', 62), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 10), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 0.9999999999913292, 'model1_rf': 1.7341529915682259e-12, 'model2_lr': 1.7341529915682259e-12, 'model4_xgb': 1.7341529915682259e-12, 'model5_lgbm': 1.7341529915682259e-12, 'model_baseline': 1.7341529915682259e-12}\n",
      "(('perm_idx', 63), ('policy', 'epsilon_greedy'), ('ucb_scale', None), ('epsilon', 0.25), ('greed_factor', 100), ('strategy', 'greedy'), ('order', 'best'), ('pool_size', 250), ('num_rounds', 50))\n",
      "Allocations after round 50 :\n",
      " {'model3_lr': 1.0, 'model1_rf': 2.459654426579843e-118, 'model2_lr': 2.459654426579843e-118, 'model4_xgb': 2.459654426579843e-118, 'model5_lgbm': 2.459654426579843e-118, 'model_baseline': 2.459654426579843e-118}\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "simulations = {}\n",
    "for _, v in permutations.items():\n",
    "    policy = v['policy']\n",
    "    ucb_scale = None\n",
    "    epsilon = None\n",
    "    greed_factor = None\n",
    "    if policy == 'UCB1':\n",
    "        for strategy, order in v['allocations']:\n",
    "            for greed_factor in v['options']['greed_factor']:\n",
    "                perm_idx = make_perm_idx(i, policy, ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                print(perm_idx)\n",
    "                timesteps = perform_simulation(allocation_pool_df, target_results_df, allocation_method, policy,\n",
    "                                               ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                payload = make_perm_dict(i, policy, ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                payload['timesteps'] = timesteps\n",
    "                simulations[perm_idx] = payload\n",
    "                i = i + 1\n",
    "    if policy == 'Bayes_UCB':\n",
    "        for strategy, order in v['allocations']:\n",
    "            for ucb_scale in v['options']['ucb_scale']:\n",
    "                for greed_factor in v['options']['greed_factor']:\n",
    "                    perm_idx = make_perm_idx(i, policy, ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                    print(perm_idx)\n",
    "                    timesteps = perform_simulation(allocation_pool_df, target_results_df, allocation_method, policy,\n",
    "                                                   ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                    payload = make_perm_dict(i, policy, ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                    payload['timesteps'] = timesteps\n",
    "                    simulations[perm_idx] = payload\n",
    "                    i = i + 1\n",
    "    if policy == 'epsilon_greedy':\n",
    "        for strategy, order in v['allocations']:\n",
    "            for epsilon in v['options']['epsilon']:\n",
    "                for greed_factor in v['options']['greed_factor']:\n",
    "                    perm_idx = make_perm_idx(i, policy, ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                    print(perm_idx)\n",
    "                    timesteps = perform_simulation(allocation_pool_df, target_results_df, allocation_method, policy,\n",
    "                                                   ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                    payload = make_perm_dict(i, policy, ucb_scale, epsilon, greed_factor, strategy, order, num_targets, simulation_rounds)\n",
    "                    payload['timesteps'] = timesteps\n",
    "                    simulations[perm_idx] = payload\n",
    "                    i = i + 1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_to_json(data):\n",
    "    if data is None or isinstance(data, (bool, int, str)):\n",
    "        return data\n",
    "    if isinstance(data, (tuple, frozenset)):\n",
    "        return str(data)\n",
    "    raise TypeError\n",
    "\n",
    "def to_json(data):\n",
    "    if data is None or isinstance(data, (bool, int, tuple, range, str, list)):\n",
    "        return data\n",
    "    if isinstance(data, (set, frozenset)):\n",
    "        return sorted(data)\n",
    "    if isinstance(data, dict):\n",
    "        return {key_to_json(key): to_json(data[key]) for key in data}\n",
    "    raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write simulation sequence to a json file\n",
    "with open('simulations.json', 'w') as json_file:\n",
    "    json.dump(simulations, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:min_ds] *",
   "language": "python",
   "name": "conda-env-min_ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
